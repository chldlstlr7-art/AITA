import os
import threading
import uuid
from dotenv import load_dotenv
load_dotenv()

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename
import uuid
from services.analysis_service import perform_full_analysis_and_comparison
from services.parsing_service import extract_text
# â¬‡ï¸ qa_service ì„í¬íŠ¸
from services.qa_service import generate_initial_questions, generate_deep_dive_question, generate_refill_questions
import random
import re
import traceback
def _parse_similarity_level(report_text):
    """
    LLMì´ ìƒì„±í•œ ë¹„êµ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ì—ì„œ 'Similarity Level'ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    (KeyëŠ” ì˜ì–´, ValueëŠ” í•œêµ­ì–´/ì˜ì–´ ëª¨ë‘ ì²˜ë¦¬)
    """
    try:
        # 1. (ìµœì¢… ìˆ˜ì •) KeyëŠ” 'Similarity Level'ë¡œ ê³ ì •, **(ë³„í‘œ)ëŠ” ì˜µì…˜
        #    re.search(r"Similarity Level:.*?\s*(.+)", ...)
        #    - 'Similarity Level:' : 'Similarity Level:' ê¸€ìë¥¼ ì°¾ìŒ
        #    - '.*?' : ':' ë’¤ì— ** ê°™ì€ ë¬¸ìê°€ ìˆë“  ì—†ë“  ëª¨ë‘ í†µê³¼ (Non-Greedy)
        #    - '\s*' : ê³µë°±ì´ ìˆë“  ì—†ë“  í†µê³¼
        #    - '(.+)' : ê³µë°± ë’¤ì˜ 'ê°’' (ì˜ˆ: 'ë‚®ìŒ')ì„ ìº¡ì²˜ (ê·¸ë£¹ 1)
        match = re.search(r"Similarity Level:.*?\s*(.+)", report_text, re.IGNORECASE)
        
        if match:
            level = match.group(1).strip().lower() # ìº¡ì²˜ëœ ê°’ (ì˜ˆ: 'ë‚®ìŒ')
            
            # 2. í•œêµ­ì–´/ì˜ì–´ ê°’ ë§¤í•‘
            if "very high" in level or "ë§¤ìš° ë†’ìŒ" in level:
                return "Very High"
            if "high" in level or "ë†’ìŒ" in level:
                return "High"
            if "moderate" in level or "ë³´í†µ" in level:
                return "Moderate"
            if "low" in level or "ë‚®ìŒ" in level:
                return "Low"
            
    except Exception as e:
        print(f"[_parse_similarity_level] íŒŒì‹± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        pass
    
    return "Unknown" # íŒŒì‹± ì‹¤íŒ¨
    
# â¬‡ï¸ ì§ˆë¬¸ ë¶„ë°°ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def _distribute_questions(questions_pool, count=3):
    """
    ì§ˆë¬¸ í’€(9ê°œ)ì—ì„œ 3ê°€ì§€ ìœ í˜•ì„ ìµœëŒ€í•œ ê· ë“±í•˜ê²Œ ì„ì–´ì„œ 3ê°œë¥¼ ë½‘ìŠµë‹ˆë‹¤.
    (ê°„ë‹¨í•œ ë²„ì „: 3ê°œ ìœ í˜•ì—ì„œ 1ê°œì”© ë½‘ê¸°)
    """
    if not questions_pool:
        return []
    
    # ìœ í˜•ë³„ë¡œ ë¶„ë¦¬
    critical_q = [q for q in questions_pool if q.get('type') == 'critical']
    perspective_q = [q for q in questions_pool if q.get('type') == 'perspective']
    innovative_q = [q for q in questions_pool if q.get('type') == 'innovative']
    
    initial_set = []
    
    # ê° í’€ì—ì„œ í•˜ë‚˜ì”© ì•ˆì „í•˜ê²Œ ë½‘ê¸°
    if critical_q:
        initial_set.append(critical_q.pop(0))
    if perspective_q:
        initial_set.append(perspective_q.pop(0))
    if innovative_q:
        initial_set.append(innovative_q.pop(0))
        
    # ë½‘íŒ ì§ˆë¬¸ì€ ì›ë³¸ í’€ì—ì„œë„ ì œê±°í•´ì•¼ í•¨ (ì¤‘ìš”)
    for q in initial_set:
        questions_pool.remove(q)
        
    return initial_set

# --- 1. Flask ì•± ì„¤ì • ---
app = Flask(__name__)
# Vercel í”„ë¡ íŠ¸ì—”ë“œ ë° ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œì˜ ì ‘ê·¼ì„ í—ˆìš© (ë§¤ìš° ì¤‘ìš”)
CORS(app, resources={r"/api/*": {"origins": ["*.vercel.app", "http://localhost:3000"]}})

# ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ì„ì‹œ ë”•ì…”ë„ˆë¦¬ (ë‚˜ì¤‘ì—” DBë¡œ)
analysis_results = {}
analysis_status = {}

def background_analysis_step1(report_id, text, doc_type, original_filename):
    """(1ë‹¨ê³„) í•µì‹¬ ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ê³ , 2ë‹¨ê³„(QA) ìŠ¤ë ˆë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    print(f"[{report_id}] Step 1 (Analysis) starting...")
    analysis_status[report_id] = "processing_analysis" # 1. ìƒíƒœ: ë¶„ì„ ì¤‘
    
    try:
        # 1. í•µì‹¬ ë¶„ì„ (analysis_service)
        analysis_data = perform_full_analysis_and_comparison(text, original_filename)
        
        if not analysis_data:
            raise Exception("perform_full_analysis_and_comparison returned None")

        print(f"[{report_id}] Step 1 (Analysis) COMPLETE. Saving partial data.")
        text_snippet = text[:4000] 

        # 2. (ì¤‘ìš”) ì§ˆë¬¸ì´ *ì—†ëŠ”* ë¶€ë¶„ì ì¸(partial) ê²°ê³¼ ì €ì¥
        partial_result = {
            "summary": analysis_data['submission_summary'], 
            "evaluation": {
                "structural_similarity_comment": "LLM ì •ë°€ ë¹„êµ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”." 
            },
            "logicFlow": {},
            "similarity_details": {
                "structural_similarity_details": analysis_data['llm_comparison_results']
            },
            "text_snippet": text_snippet, # (QAê°€ ë‚˜ì¤‘ì— ì‚¬ìš©í•  ì¬ë£Œ)
            "initialQuestions": [],   # (ì•„ì§ ë¹„ì–´ìˆìŒ)
            "questions_pool": [],     # (ì•„ì§ ë¹„ì–´ìˆìŒ)
            "qa_history": [],
            "is_refilling": False
        }
        
        analysis_results[report_id] = partial_result
        analysis_status[report_id] = "processing_questions" # 2. ìƒíƒœ: ì§ˆë¬¸ ìƒì„± ì¤‘

        # 3. 2ë‹¨ê³„(QA) ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¥¼ ì¦‰ì‹œ í˜¸ì¶œ
        print(f"[{report_id}] Triggering Step 2 (QA) in background...")
        qa_thread = threading.Thread(target=background_analysis_step2_qa, args=(report_id,))
        qa_thread.start()

    except Exception as e:
        print(f"[{report_id}] Step 1 (Analysis) FAILED: {e}")
        analysis_status[report_id] = "error"
        analysis_results[report_id] = {"error": str(e)}

def background_analysis_step2_qa(report_id):
    """(2ë‹¨ê³„) QA ì§ˆë¬¸ë§Œ ìƒì„±í•´ì„œ ê¸°ì¡´ ê²°ê³¼ì— appendí•©ë‹ˆë‹¤."""
    
    print(f"[{report_id}] Step 2 (QA) thread started...")
    try:
        # 1ë‹¨ê³„ì—ì„œ ì €ì¥í•œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        report = analysis_results.get(report_id)
        if not report:
            raise Exception("Report data not found for QA generation")

        summary = report["summary"]
        similar = report["similarity_details"]["structural_similarity_details"]
        snippet = report["text_snippet"]
        
        # 1. ëª¨ë“  í›„ë³´ ë³´ê³ ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        all_candidate_reports = report["similarity_details"]["structural_similarity_details"]
        
        # 2. 'High' ë˜ëŠ” 'Very High'ì¸ ë³´ê³ ì„œë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
        high_similarity_reports = []
        for candidate_report in all_candidate_reports:
            report_text = candidate_report.get("llm_comparison_report", "")
            level = _parse_similarity_level(report_text)
            
            if level in ["High", "Very High"]:
                high_similarity_reports.append(candidate_report)
                
        print(f"[{report_id}] QA Filter: Found {len(high_similarity_reports)} 'High/Very High' reports.")
        
        # 3. 9ê°œì˜ ì§ˆë¬¸ í’€ ìƒì„± (qa_service)
        questions_pool = generate_initial_questions(summary, similar, snippet)
        
        if not questions_pool:
            print(f"[{report_id}] WARNING: QA generation failed. Using dummies.")
            questions_pool = [
                {"type": "critical", "question": "ì„ì‹œ ì§ˆë¬¸ 1: ì£¼ì¥ì˜ ê·¼ê±°ê°€ ì•½í•©ë‹ˆë‹¤."},
                {"type": "perspective", "question": "ì„ì‹œ ì§ˆë¬¸ 2: ë‹¤ë¥¸ ê´€ì ì€ ì—†ë‚˜ìš”?"},
                {"type": "innovative", "question": "ì„ì‹œ ì§ˆë¬¸ 3: ê·¸ë˜ì„œ ì–´ë–»ê²Œ ì ìš©í•˜ì£ ?"}
            ]
        
        # 4. 3ê°œ ë¶„ë°°
        initial_questions_raw = _distribute_questions(questions_pool, 3)
        report["questions_pool"] = questions_pool

        # qa_historyê°€ 1ë‹¨ê³„ì—ì„œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ë°©ì–´ ì½”ë“œ)
        if "qa_history" not in report:
            report["qa_history"] = []
            
        initial_questions_for_client = [] # í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë³´ë‚¼ ë¦¬ìŠ¤íŠ¸

        for q_data in initial_questions_raw:
            # 4-1. ê³ ìœ  ID ìƒì„±
            q_id = str(uuid.uuid4())
            
            # 4-2. qa_historyì— (answer: null) ìƒíƒœë¡œ ì €ì¥
            history_entry = {
                "question_id": q_id,
                "question": q_data.get("question", "Failed to parse"),
                "type": q_data.get("type", "unknown"),
                "answer": None,
                "parent_question_id": None # ìµœìƒìœ„ ì§ˆë¬¸
            }
            report["qa_history"].append(history_entry)
            
            # 4-3. í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë³´ë‚¼ ë¦¬ìŠ¤íŠ¸ì— IDì™€ í•¨ê»˜ ì¶”ê°€
            client_entry = {
                "question_id": q_id,
                "question": q_data.get("question", "Failed to parse"),
                "type": q_data.get("type", "unknown")
            }
            initial_questions_for_client.append(client_entry)

        # 5. (ìˆ˜ì •) í´ë¼ì´ì–¸íŠ¸ìš© ë¦¬ìŠ¤íŠ¸ë¥¼ initialQuestionsì— ì €ì¥
        report["initialQuestions"] = initial_questions_for_client
        
        
        analysis_status[report_id] = "completed" # 3. ìƒíƒœ: ëª¨ë“  ì‘ì—… ì™„ë£Œ
        print(f"[{report_id}] Step 2 (QA) COMPLETE. Status set to 'completed'.")

    except Exception as e:
        print(f"[{report_id}] Step 2 (QA) FAILED: {e}")

        # â¬‡ï¸ 2. (ì¶”ê°€) ì—ëŸ¬ì˜ ì „ì²´ ì„¸ë¶€ ì •ë³´ë¥¼ í„°ë¯¸ë„ì— ì¶œë ¥
        print("\n--- ğŸš¨ Step 2 (QA) FULL TRACEBACK ğŸš¨ ---")
        traceback.print_exc()
        print("-------------------------------------------\n")
        # â¬†ï¸ (ì¶”ê°€ ë)

        analysis_status[report_id] = "completed"


# app.py

def background_refill(report_id):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§ˆë¬¸ í’€ì„ 6ê°œ ë¦¬í•„í•˜ê³  ì ê¸ˆì„ í•´ì œí•©ë‹ˆë‹¤.
    """
    report = analysis_results.get(report_id)
    if not report:
        print(f"[{report_id}] Refill FAILED: Report not found.")
        return

    print(f"[{report_id}] Refill thread started...")
    
    try:
        # ë¦¬í•„ì— í•„ìš”í•œ ì¬ë£Œ (summary, similar, snippet)
        summary = report["summary"]
        similar = report["similarity_details"]["structural_similarity_details"]
        text_snippet = report.get("text_snippet", "")
        
        # â­ï¸ qa_serviceì˜ 6ê°œ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
        new_questions = generate_refill_questions(summary, similar, text_snippet)
        
        if new_questions:
            report["questions_pool"].extend(new_questions)
            print(f"[{report_id}] Refill complete. New pool size: {len(report['questions_pool'])}")
        else:
            print(f"[{report_id}] Refill FAILED: generate_refill_questions returned None")
            
    except Exception as e:
        print(f"[{report_id}] Refill thread error: {e}")
        
    finally:
        # â­ï¸ (ì¤‘ìš”) ì„±ê³µí•˜ë“  ì‹¤íŒ¨í•˜ë“ , ì ê¸ˆì„ í•´ì œí•©ë‹ˆë‹¤.
        report["is_refilling"] = False
        print(f"[{report_id}] Refill lock released.")

@app.route("/api/analyze", methods=["POST"])
def analyze_report():
    """
    POST /api/analyze
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ íŒŒì¼ê³¼ í¼ ë°ì´í„°ë¥¼ ë°›ì•„ ë¶„ì„ì„ 'ì‹œì‘'ì‹œí‚´
    """
    
    # (íŒŒì¼ íŒŒì‹± ë¡œì§)
    file = request.files.get("file")
    text = request.form.get("text")
    doc_type = request.form.get("docType")
    original_filename = "new_submission.txt" # ê¸°ë³¸ê°’

    if not text and file:
        original_filename = secure_filename(file.filename)
        text = extract_text(file) # parsing_service.py
    elif text:
        pass # í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ ì‚¬ìš©
    else:
        return jsonify({"error": "No content provided (file or text)"}), 400
    
    if not text or len(text) < 50:
        return jsonify({"error": "Text is too short for analysis"}), 400

    report_id = str(uuid.uuid4())
    analysis_status[report_id] = "processing"
    
    # (ë§¤ìš° ì¤‘ìš”) ë¶„ì„ì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹œì‘ì‹œí‚´
    thread = threading.Thread(
        target=background_analysis_step1,
        args=(report_id, text, doc_type, original_filename)
    )
    thread.start()
    
    # í”„ë¡ íŠ¸ì—”ë“œì—ëŠ” ì¦‰ì‹œ reportIdë¥¼ ë°˜í™˜ (202 Accepted)
    return jsonify({"reportId": report_id}), 202


# â¬‡ï¸â¬‡ï¸â¬‡ï¸ 3. (ìˆ˜ì •) /api/report/<report_id> ì—”ë“œí¬íŠ¸ â¬‡ï¸â¬‡ï¸â¬‡ï¸
@app.route("/api/report/<report_id>", methods=["GET"])
def get_report(report_id):
    """
    GET /api/report/<report_id>
    ë¶„ì„ ìƒíƒœì™€ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ìƒíƒœ ì„¸ë¶„í™”)
    """
    status = analysis_status.get(report_id)
    report_data = analysis_results.get(report_id)

    if not status:
        return jsonify({"error": "Report not found"}), 404

    if status == "processing_analysis":
        # 1. ì•„ì§ ë¶„ì„ ì¤‘
        return jsonify({"status": "processing_analysis", "data": None})

    if status == "processing_questions":
        # 2. ë¶„ì„ ì™„ë£Œ, QA ìƒì„± ì¤‘ (í”„ë¡ íŠ¸ê°€ ì´ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ìˆìŒ)
        return jsonify({"status": "processing_questions", "data": report_data})

    if status == "completed":
        # 3. ëª¨ë“  ì‘ì—… ì™„ë£Œ (QA ì§ˆë¬¸ í¬í•¨)
        return jsonify({"status": "completed", "data": report_data})
        
    if status == "error":
        # 4. 1ë‹¨ê³„(ë¶„ì„)ì—ì„œ ì˜¤ë¥˜ ë°œìƒ
        return jsonify({"status": "error", "data": report_data}), 500

# --- â¬‡ï¸ 6. (ì¶”ê°€) QA ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ìƒˆ API ì—”ë“œí¬ì¸íŠ¸ ---



@app.route("/api/report/<report_id>/question/next", methods=["POST"])
def get_next_question(report_id):
    """
    POST /api/report/<report_id>/question/next
    ì‚¬ìš©ìê°€ 'ìƒˆë¡œê³ ì¹¨' ë˜ëŠ” 'ì¶”ê°€ ì§ˆë¬¸'ì„ ìš”ì²­í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    (ìµœì¢…ë³¸: '2ê°œ ì´í•˜ì¼ ë•Œ ë°±ê·¸ë¼ìš´ë“œ ë¦¬í•„' ë¡œì§ í¬í•¨)
    """
    report = analysis_results.get(report_id)
    if not report or "questions_pool" not in report:
        return jsonify({"error": "Report not found or not completed"}), 404

    pool = report["questions_pool"]
    is_refilling = report.get("is_refilling", False) # ìƒíƒœ ì ê¸ˆ í™•ì¸

    if not pool:
        if is_refilling:
            # í’€ì´ ë¹„ì—ˆì§€ë§Œ ë¦¬í•„ ì¤‘ì¼ ë•Œ
            return jsonify({"error": "No questions available, refill in progress. Please wait."}), 503
        else:
            # í’€ì´ ë¹„ì—ˆê³  ë¦¬í•„ ì¤‘ë„ ì•„ë‹ ë•Œ (ë¹„ìƒ ìƒí™©)
            print(f"[{report_id}] Pool is empty and not refilling. Triggering emergency refill.")
            report["is_refilling"] = True
            refill_thread = threading.Thread(target=background_refill, args=(report_id,))
            refill_thread.start()
            return jsonify({"error": "No questions available, starting emergency refill. Please wait."}), 503

    # â¬‡ï¸â¬‡ï¸â¬‡ï¸ ì—¬ê¸°ê°€ í•µì‹¬ ë¡œì§ â¬‡ï¸â¬‡ï¸â¬‡ï¸
    # 1. í’€ì—ì„œ í•˜ë‚˜ë¥¼ ë½‘ì•„ì„œ ë°˜í™˜
    next_question = pool.pop(0)
    
    # 2. (í•µì‹¬) ë‚¨ì€ ì§ˆë¬¸ì´ 2ê°œ ì´í•˜ì´ê³ , *í˜„ì¬ ë¦¬í•„ ì¤‘ì´ ì•„ë‹ ë•Œ*
    if len(pool) <= 2 and not is_refilling:
        print(f"[{report_id}] Pool size ({len(pool)}) <= 2. Triggering background refill.")
        # ì¦‰ì‹œ ì ê¸ˆ
        report["is_refilling"] = True
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        refill_thread = threading.Thread(target=background_refill, args=(report_id,))
        refill_thread.start()
    # â¬†ï¸â¬†ï¸â¬†ï¸ í•µì‹¬ ë¡œì§ ë â¬†ï¸â¬†ï¸â¬†ï¸

    # (ì„ íƒ) ë½‘ì€ ì§ˆë¬¸ì„ QA ê¸°ë¡ìœ¼ë¡œ ì´ë™
    if "qa_history" not in report:
        report["qa_history"] = []


    # 4. ê³ ìœ  ID ìƒì„± ë° qa_historyì— ì¶”ê°€
    question_id = str(uuid.uuid4())
    
    # qa_historyì— ì €ì¥í•  ë°ì´í„°
    history_entry = {
        "question_id": question_id, # â¬…ï¸ ê³ ìœ  ID ì¶”ê°€
        "question": next_question.get("question", "Failed to parse question"),
        "type": next_question.get("type", "unknown"),
        "answer": None, # ë‹µë³€ ëŒ€ê¸°
        "parent_question_id": None
    }
    report["qa_history"].append(history_entry)

    # 5. í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë°˜í™˜í•  ë°ì´í„° (ID í¬í•¨)
    # (ì£¼ì˜: history_entry ì „ì²´ê°€ ì•„ë‹Œ, í•„ìš”í•œ ì •ë³´ë§Œ ë°˜í™˜)
    client_response = {
        "question_id": question_id, # â¬…ï¸ í´ë¼ì´ì–¸íŠ¸ê°€ ì´ IDë¥¼ ë°›ì•„ì•¼ í•¨
        "question": history_entry["question"],
        "type": history_entry["type"]
    }

    return jsonify(client_response)

@app.route("/api/report/<report_id>/answer", methods=["POST"])
def submit_answer(report_id):
    """
    POST /api/report/<report_id>/answer
    ì‚¬ìš©ìê°€ ì¼ë°˜/ì‹¬í™” ì§ˆë¬¸ì— ëŒ€í•œ 'ë‹µë³€ë§Œ' ì œì¶œí•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    (ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì‹¬í™” ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)
    """
    report = analysis_results.get(report_id)
    if not report:
        return jsonify({"error": "Report not found"}), 404
    
    data = request.json
    # â¬‡ï¸â¬‡ï¸â¬‡ï¸ [ìˆ˜ì •ëœ ë¶€ë¶„] â¬‡ï¸â¬‡ï¸â¬‡ï¸
    # 1. í…ìŠ¤íŠ¸ ëŒ€ì‹  'question_id'ë¥¼ ë°›ìŒ
    question_id = data.get("question_id") 
    user_answer = data.get("user_answer")

    if not question_id or user_answer is None: 
        return jsonify({"error": "Missing question_id or user_answer"}), 400

    # user_answerëŠ” ë¹ˆ ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ Noneê³¼ ë¹„êµ
    if not original_question or user_answer is None: 
        return jsonify({"error": "Missing original_question or user_answer"}), 400

    if "qa_history" not in report:
        report["qa_history"] = []

    # 2. qa_historyì—ì„œ 'question_id'ë¡œ í•´ë‹¹ ì§ˆë¬¸ì„ ì°¾ì•„ ë‹µë³€ì„ ì—…ë°ì´íŠ¸
    history_updated = False
    for item in reversed(report["qa_history"]): # ìµœê·¼ í•­ëª©ë¶€í„° ê²€ìƒ‰
        if item.get("question_id") == question_id and item.get("answer") is None:
            item["answer"] = user_answer # ì‚¬ìš©ì ë‹µë³€ ì¶”ê°€
            history_updated = True
            break
    # (ì˜ˆì™¸ ì²˜ë¦¬) historyì— ì§ˆë¬¸ì´ ì—†ëŠ” ê²½ìš°
    if not history_updated:
        print(f"[{report_id}] WARNING: submit_answer couldn't find matching question. Appending new.")
        report["qa_history"].append({
            "question": original_question,
            "type": "unknown_submission", # íƒ€ì…ì„ ì•Œ ìˆ˜ ì—†ìŒ
            "answer": user_answer
        })
        
    print(f"[{report_id}] Answer saved successfully.")
    return jsonify({"status": "success", "message": "Answer saved successfully"})

@app.route("/api/report/<report_id>/question/deep-dive", methods=["POST"])
def post_deep_dive_question(report_id):
    """
    POST /api/report/<report_id>/question/deep-dive
    (ìˆ˜ì •) 'parent_question_id'ë¥¼ ë°›ì•„, *ì „ì²´ ëŒ€í™” ë§¥ë½*ì„ 
    ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ì‹¬í™” ì§ˆë¬¸ì„ ìƒì„±
    """
    report = analysis_results.get(report_id)
    if not report or "qa_history" not in report:
        return jsonify({"error": "Report not found or history is empty"}), 404
        
    data = request.json
    parent_question_id = data.get("parent_question_id") # (ì˜ˆ: Q1.1ì˜ ID)
    if not parent_question_id:
        return jsonify({"error": "Missing parent_question_id to deep-dive from"}), 400

    # 1. (í•µì‹¬) ëŒ€í™” ì²´ì¸ ì¬êµ¬ì„± (Recursive chain traversal)
    # -----------------------------------------------------------------
    # í¸ì˜ë¥¼ ìœ„í•´ qa_historyë¥¼ ID ê¸°ë°˜ ë§µìœ¼ë¡œ ë³€í™˜
    history_map = {item['question_id']: item for item in report["qa_history"]}
    
    conversation_history_list = [] # LLMì— ì „ë‹¬í•  Q/A ìŒ ë¦¬ìŠ¤íŠ¸
    current_id = parent_question_id

    while current_id is not None:
        if current_id not in history_map:
            print(f"[{report_id}] CRITICAL: History chain broken. ID {current_id} not found.")
            break # ì²´ì¸ì´ ëŠê¸°ë©´ íƒìƒ‰ ì¤‘ì§€
        
        parent_qa = history_map[current_id]
        
        # ë‹µë³€ì´ ì—†ëŠ” Q/A ìŒì€ ë§¥ë½ì— í¬í•¨í•  ìˆ˜ ì—†ìŒ
        if parent_qa.get("answer") is None:
            # (ì˜ˆì™¸) ë‹¨, ì§€ê¸ˆ ë§‰ ë‹µë³€í•œ 'ì²« ë²ˆì§¸ ë¶€ëª¨'ëŠ” ë°˜ë“œì‹œ ë‹µë³€ì´ ìˆì–´ì•¼ í•¨
            if current_id == parent_question_id:
                 return jsonify({"error": f"Parent question ID {parent_question_id} has not been answered yet."}), 400
            # ê·¸ ì´ì „ì˜ ë¶€ëª¨ê°€ ë‹µë³€ì´ ì—†ìœ¼ë©´ íƒìƒ‰ ì¤‘ì§€
            break

        # Q/A ìŒì„ ë¦¬ìŠ¤íŠ¸ *ì•ìª½*ì— ì¶”ê°€ (ì˜¤ë˜ëœ ê²ƒì´ 0ë²ˆ ì¸ë±ìŠ¤ê°€ ë˜ë„ë¡)
        conversation_history_list.insert(0, {
            "question": parent_qa.get("question"),
            "answer": parent_qa.get("answer")
        })
        
        # ë‹¤ìŒ ë¶€ëª¨ë¡œ ì´ë™
        current_id = parent_qa.get("parent_question_id")

    if not conversation_history_list:
        return jsonify({"error": f"Could not reconstruct valid history for {parent_question_id}."}), 404
    # -----------------------------------------------------------------

    # 2. (ìˆ˜ì •) qa_serviceì˜ í•¨ìˆ˜ì— *ì „ì²´ íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸* ì „ë‹¬
    deep_dive_question_text = generate_deep_dive_question(
        conversation_history_list, # â¬…ï¸ [í•µì‹¬] ì „ì²´ ë§¥ë½ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
        report["summary"] 
    )
    
    if not deep_dive_question_text:
        return jsonify({"error": "Failed to generate deep-dive question"}), 

    # 3. (ê¸°ì¡´ ë¡œì§) ìƒˆ ì§ˆë¬¸ì„ 'ì—°ê²°'í•˜ì—¬ ì €ì¥
    new_question_id = str(uuid.uuid4())
    
    history_entry = {
        "question_id": new_question_id, 
        "question": deep_dive_question_text,
        "type": "deep_dive", 
        "answer": None,
        "parent_question_id": parent_question_id # â¬…ï¸ ë¶€ëª¨ëŠ” *ì§ì „*ì˜ ID
    }
    report["qa_history"].append(history_entry)

    # 4. (ê¸°ì¡´ ë¡œì§) ìƒˆ ì§ˆë¬¸ ì •ë³´ ë°˜í™˜
    client_response = {
        "question_id": new_question_id,
        "question": deep_dive_question_text
    }

    return jsonify(client_response)
    
# --- 4. (ì„ íƒ ì‚¬í•­) ë£¨íŠ¸ í™•ì¸ìš© ---
@app.route("/")
def hello_world():
    return jsonify({"message": "AITA Backend is running!"})
