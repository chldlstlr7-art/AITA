import os
import threading
import uuid
from dotenv import load_dotenv
load_dotenv()

from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename

from services.analysis_service import perform_full_analysis_and_comparison
from services.parsing_service import extract_text
# â¬‡ï¸ qa_service ì„í¬íŠ¸
from services.qa_service import generate_initial_questions, generate_deep_dive_question, generate_refill_questions
import random
import re
import traceback
def _parse_similarity_level(report_text):
    """
    LLMì´ ìƒì„±í•œ ë¹„êµ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ì—ì„œ 'Similarity Level'ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    (KeyëŠ” ì˜ì–´, ValueëŠ” í•œêµ­ì–´/ì˜ì–´ ëª¨ë‘ ì²˜ë¦¬)
    """
    try:
        # 1. (ìµœì¢… ìˆ˜ì •) KeyëŠ” 'Similarity Level'ë¡œ ê³ ì •, **(ë³„í‘œ)ëŠ” ì˜µì…˜
        #    re.search(r"Similarity Level:.*?\s*(.+)", ...)
        #    - 'Similarity Level:' : 'Similarity Level:' ê¸€ìë¥¼ ì°¾ìŒ
        #    - '.*?' : ':' ë’¤ì— ** ê°™ì€ ë¬¸ìê°€ ìˆë“  ì—†ë“  ëª¨ë‘ í†µê³¼ (Non-Greedy)
        #    - '\s*' : ê³µë°±ì´ ìˆë“  ì—†ë“  í†µê³¼
        #    - '(.+)' : ê³µë°± ë’¤ì˜ 'ê°’' (ì˜ˆ: 'ë‚®ìŒ')ì„ ìº¡ì²˜ (ê·¸ë£¹ 1)
        match = re.search(r"Similarity Level:.*?\s*(.+)", report_text, re.IGNORECASE)
        
        if match:
            level = match.group(1).strip().lower() # ìº¡ì²˜ëœ ê°’ (ì˜ˆ: 'ë‚®ìŒ')
            
            # 2. í•œêµ­ì–´/ì˜ì–´ ê°’ ë§¤í•‘
            if "very high" in level or "ë§¤ìš° ë†’ìŒ" in level:
                return "Very High"
            if "high" in level or "ë†’ìŒ" in level:
                return "High"
            if "moderate" in level or "ë³´í†µ" in level:
                return "Moderate"
            if "low" in level or "ë‚®ìŒ" in level:
                return "Low"
            
    except Exception as e:
        print(f"[_parse_similarity_level] íŒŒì‹± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        pass
    
    return "Unknown" # íŒŒì‹± ì‹¤íŒ¨
    
# â¬‡ï¸ ì§ˆë¬¸ ë¶„ë°°ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def _distribute_questions(questions_pool, count=3):
    """
    ì§ˆë¬¸ í’€(9ê°œ)ì—ì„œ 3ê°€ì§€ ìœ í˜•ì„ ìµœëŒ€í•œ ê· ë“±í•˜ê²Œ ì„ì–´ì„œ 3ê°œë¥¼ ë½‘ìŠµë‹ˆë‹¤.
    (ê°„ë‹¨í•œ ë²„ì „: 3ê°œ ìœ í˜•ì—ì„œ 1ê°œì”© ë½‘ê¸°)
    """
    if not questions_pool:
        return []
    
    # ìœ í˜•ë³„ë¡œ ë¶„ë¦¬
    critical_q = [q for q in questions_pool if q.get('type') == 'critical']
    perspective_q = [q for q in questions_pool if q.get('type') == 'perspective']
    innovative_q = [q for q in questions_pool if q.get('type') == 'innovative']
    
    initial_set = []
    
    # ê° í’€ì—ì„œ í•˜ë‚˜ì”© ì•ˆì „í•˜ê²Œ ë½‘ê¸°
    if critical_q:
        initial_set.append(critical_q.pop(0))
    if perspective_q:
        initial_set.append(perspective_q.pop(0))
    if innovative_q:
        initial_set.append(innovative_q.pop(0))
        
    # ë½‘íŒ ì§ˆë¬¸ì€ ì›ë³¸ í’€ì—ì„œë„ ì œê±°í•´ì•¼ í•¨ (ì¤‘ìš”)
    for q in initial_set:
        questions_pool.remove(q)
        
    return initial_set

# --- 1. Flask ì•± ì„¤ì • ---
app = Flask(__name__)
# Vercel í”„ë¡ íŠ¸ì—”ë“œ ë° ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œì˜ ì ‘ê·¼ì„ í—ˆìš© (ë§¤ìš° ì¤‘ìš”)
CORS(app, resources={r"/api/*": {"origins": ["*.vercel.app", "http://localhost:3000"]}})

# ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ì„ì‹œ ë”•ì…”ë„ˆë¦¬ (ë‚˜ì¤‘ì—” DBë¡œ)
analysis_results = {}
analysis_status = {}

def background_analysis_step1(report_id, text, doc_type, original_filename):
    """(1ë‹¨ê³„) í•µì‹¬ ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ê³ , 2ë‹¨ê³„(QA) ìŠ¤ë ˆë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    
    print(f"[{report_id}] Step 1 (Analysis) starting...")
    analysis_status[report_id] = "processing_analysis" # 1. ìƒíƒœ: ë¶„ì„ ì¤‘
    
    try:
        # 1. í•µì‹¬ ë¶„ì„ (analysis_service)
        analysis_data = perform_full_analysis_and_comparison(text, original_filename)
        
        if not analysis_data:
            raise Exception("perform_full_analysis_and_comparison returned None")

        print(f"[{report_id}] Step 1 (Analysis) COMPLETE. Saving partial data.")
        text_snippet = text[:4000] 

        # 2. (ì¤‘ìš”) ì§ˆë¬¸ì´ *ì—†ëŠ”* ë¶€ë¶„ì ì¸(partial) ê²°ê³¼ ì €ì¥
        partial_result = {
            "summary": analysis_data['submission_summary'], 
            "evaluation": {
                "structural_similarity_comment": "LLM ì •ë°€ ë¹„êµ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”." 
            },
            "logicFlow": {},
            "similarity_details": {
                "structural_similarity_details": analysis_data['llm_comparison_results']
            },
            "text_snippet": text_snippet, # (QAê°€ ë‚˜ì¤‘ì— ì‚¬ìš©í•  ì¬ë£Œ)
            "initialQuestions": [],   # (ì•„ì§ ë¹„ì–´ìˆìŒ)
            "questions_pool": [],     # (ì•„ì§ ë¹„ì–´ìˆìŒ)
            "qa_history": [],
            "is_refilling": False
        }
        
        analysis_results[report_id] = partial_result
        analysis_status[report_id] = "processing_questions" # 2. ìƒíƒœ: ì§ˆë¬¸ ìƒì„± ì¤‘

        # 3. 2ë‹¨ê³„(QA) ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¥¼ ì¦‰ì‹œ í˜¸ì¶œ
        print(f"[{report_id}] Triggering Step 2 (QA) in background...")
        qa_thread = threading.Thread(target=background_analysis_step2_qa, args=(report_id,))
        qa_thread.start()

    except Exception as e:
        print(f"[{report_id}] Step 1 (Analysis) FAILED: {e}")
        analysis_status[report_id] = "error"
        analysis_results[report_id] = {"error": str(e)}

def background_analysis_step2_qa(report_id):
    """(2ë‹¨ê³„) QA ì§ˆë¬¸ë§Œ ìƒì„±í•´ì„œ ê¸°ì¡´ ê²°ê³¼ì— appendí•©ë‹ˆë‹¤."""
    
    print(f"[{report_id}] Step 2 (QA) thread started...")
    try:
        # 1ë‹¨ê³„ì—ì„œ ì €ì¥í•œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        report = analysis_results.get(report_id)
        if not report:
            raise Exception("Report data not found for QA generation")

        summary = report["summary"]
        similar = report["similarity_details"]["structural_similarity_details"]
        snippet = report["text_snippet"]
        
        # 1. ëª¨ë“  í›„ë³´ ë³´ê³ ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        all_candidate_reports = report["similarity_details"]["structural_similarity_details"]
        
        # 2. 'High' ë˜ëŠ” 'Very High'ì¸ ë³´ê³ ì„œë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
        high_similarity_reports = []
        for candidate_report in all_candidate_reports:
            report_text = candidate_report.get("llm_comparison_report", "")
            level = _parse_similarity_level(report_text)
            
            if level in ["High", "Very High"]:
                high_similarity_reports.append(candidate_report)
                
        print(f"[{report_id}] QA Filter: Found {len(high_similarity_reports)} 'High/Very High' reports.")
        
        # 3. 9ê°œì˜ ì§ˆë¬¸ í’€ ìƒì„± (qa_service)
        questions_pool = generate_initial_questions(summary, similar, snippet)
        
        if not questions_pool:
            print(f"[{report_id}] WARNING: QA generation failed. Using dummies.")
            questions_pool = [
                {"type": "critical", "question": "ì„ì‹œ ì§ˆë¬¸ 1: ì£¼ì¥ì˜ ê·¼ê±°ê°€ ì•½í•©ë‹ˆë‹¤."},
                {"type": "perspective", "question": "ì„ì‹œ ì§ˆë¬¸ 2: ë‹¤ë¥¸ ê´€ì ì€ ì—†ë‚˜ìš”?"},
                {"type": "innovative", "question": "ì„ì‹œ ì§ˆë¬¸ 3: ê·¸ë˜ì„œ ì–´ë–»ê²Œ ì ìš©í•˜ì£ ?"}
            ]
        
        # 4. 3ê°œ ë¶„ë°°
        initial_questions = _distribute_questions(questions_pool, 3)
        
        # 5. (ì¤‘ìš”) ê¸°ì¡´ report ê°ì²´ì— ì§ˆë¬¸ ë°ì´í„° *ì—…ë°ì´íŠ¸*
        report["initialQuestions"] = initial_questions
        report["questions_pool"] = questions_pool
        
        analysis_status[report_id] = "completed" # 3. ìƒíƒœ: ëª¨ë“  ì‘ì—… ì™„ë£Œ
        print(f"[{report_id}] Step 2 (QA) COMPLETE. Status set to 'completed'.")

    except Exception as e:
        print(f"[{report_id}] Step 2 (QA) FAILED: {e}")

        # â¬‡ï¸ 2. (ì¶”ê°€) ì—ëŸ¬ì˜ ì „ì²´ ì„¸ë¶€ ì •ë³´ë¥¼ í„°ë¯¸ë„ì— ì¶œë ¥
        print("\n--- ğŸš¨ Step 2 (QA) FULL TRACEBACK ğŸš¨ ---")
        traceback.print_exc()
        print("-------------------------------------------\n")
        # â¬†ï¸ (ì¶”ê°€ ë)

        analysis_status[report_id] = "completed"


# app.py

def background_refill(report_id):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§ˆë¬¸ í’€ì„ 6ê°œ ë¦¬í•„í•˜ê³  ì ê¸ˆì„ í•´ì œí•©ë‹ˆë‹¤.
    """
    report = analysis_results.get(report_id)
    if not report:
        print(f"[{report_id}] Refill FAILED: Report not found.")
        return

    print(f"[{report_id}] Refill thread started...")
    
    try:
        # ë¦¬í•„ì— í•„ìš”í•œ ì¬ë£Œ (summary, similar, snippet)
        summary = report["summary"]
        similar = report["similarity_details"]["structural_similarity_details"]
        text_snippet = report.get("text_snippet", "")
        
        # â­ï¸ qa_serviceì˜ 6ê°œ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
        new_questions = generate_refill_questions(summary, similar, text_snippet)
        
        if new_questions:
            report["questions_pool"].extend(new_questions)
            print(f"[{report_id}] Refill complete. New pool size: {len(report['questions_pool'])}")
        else:
            print(f"[{report_id}] Refill FAILED: generate_refill_questions returned None")
            
    except Exception as e:
        print(f"[{report_id}] Refill thread error: {e}")
        
    finally:
        # â­ï¸ (ì¤‘ìš”) ì„±ê³µí•˜ë“  ì‹¤íŒ¨í•˜ë“ , ì ê¸ˆì„ í•´ì œí•©ë‹ˆë‹¤.
        report["is_refilling"] = False
        print(f"[{report_id}] Refill lock released.")

@app.route("/api/analyze", methods=["POST"])
def analyze_report():
    """
    POST /api/analyze
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ íŒŒì¼ê³¼ í¼ ë°ì´í„°ë¥¼ ë°›ì•„ ë¶„ì„ì„ 'ì‹œì‘'ì‹œí‚´
    """
    
    # (íŒŒì¼ íŒŒì‹± ë¡œì§)
    file = request.files.get("file")
    text = request.form.get("text")
    doc_type = request.form.get("docType")
    original_filename = "new_submission.txt" # ê¸°ë³¸ê°’

    if not text and file:
        original_filename = secure_filename(file.filename)
        text = extract_text(file) # parsing_service.py
    elif text:
        pass # í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ ì‚¬ìš©
    else:
        return jsonify({"error": "No content provided (file or text)"}), 400
    
    if not text or len(text) < 50:
        return jsonify({"error": "Text is too short for analysis"}), 400

    report_id = str(uuid.uuid4())
    analysis_status[report_id] = "processing"
    
    # (ë§¤ìš° ì¤‘ìš”) ë¶„ì„ì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹œì‘ì‹œí‚´
    thread = threading.Thread(
        target=background_analysis_step1,
        args=(report_id, text, doc_type, original_filename)
    )
    thread.start()
    
    # í”„ë¡ íŠ¸ì—”ë“œì—ëŠ” ì¦‰ì‹œ reportIdë¥¼ ë°˜í™˜ (202 Accepted)
    return jsonify({"reportId": report_id}), 202


# â¬‡ï¸â¬‡ï¸â¬‡ï¸ 3. (ìˆ˜ì •) /api/report/<report_id> ì—”ë“œí¬íŠ¸ â¬‡ï¸â¬‡ï¸â¬‡ï¸
@app.route("/api/report/<report_id>", methods=["GET"])
def get_report(report_id):
    """
    GET /api/report/<report_id>
    ë¶„ì„ ìƒíƒœì™€ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ìƒíƒœ ì„¸ë¶„í™”)
    """
    status = analysis_status.get(report_id)
    report_data = analysis_results.get(report_id)

    if not status:
        return jsonify({"error": "Report not found"}), 404

    if status == "processing_analysis":
        # 1. ì•„ì§ ë¶„ì„ ì¤‘
        return jsonify({"status": "processing_analysis", "data": None})

    if status == "processing_questions":
        # 2. ë¶„ì„ ì™„ë£Œ, QA ìƒì„± ì¤‘ (í”„ë¡ íŠ¸ê°€ ì´ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ìˆìŒ)
        return jsonify({"status": "processing_questions", "data": report_data})

    if status == "completed":
        # 3. ëª¨ë“  ì‘ì—… ì™„ë£Œ (QA ì§ˆë¬¸ í¬í•¨)
        return jsonify({"status": "completed", "data": report_data})
        
    if status == "error":
        # 4. 1ë‹¨ê³„(ë¶„ì„)ì—ì„œ ì˜¤ë¥˜ ë°œìƒ
        return jsonify({"status": "error", "data": report_data}), 500

# --- â¬‡ï¸ 6. (ì¶”ê°€) QA ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ìƒˆ API ì—”ë“œí¬ì¸íŠ¸ ---

# app.py

@app.route("/api/report/<report_id>/question/next", methods=["POST"])
def get_next_question(report_id):
    """
    POST /api/report/<report_id>/question/next
    ì‚¬ìš©ìê°€ 'ìƒˆë¡œê³ ì¹¨' ë˜ëŠ” 'ì¶”ê°€ ì§ˆë¬¸'ì„ ìš”ì²­í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    (ìµœì¢…ë³¸: '2ê°œ ì´í•˜ì¼ ë•Œ ë°±ê·¸ë¼ìš´ë“œ ë¦¬í•„' ë¡œì§ í¬í•¨)
    """
    report = analysis_results.get(report_id)
    if not report or "questions_pool" not in report:
        return jsonify({"error": "Report not found or not completed"}), 404

    pool = report["questions_pool"]
    is_refilling = report.get("is_refilling", False) # ìƒíƒœ ì ê¸ˆ í™•ì¸

    if not pool:
        if is_refilling:
            # í’€ì´ ë¹„ì—ˆì§€ë§Œ ë¦¬í•„ ì¤‘ì¼ ë•Œ
            return jsonify({"error": "No questions available, refill in progress. Please wait."}), 503
        else:
            # í’€ì´ ë¹„ì—ˆê³  ë¦¬í•„ ì¤‘ë„ ì•„ë‹ ë•Œ (ë¹„ìƒ ìƒí™©)
            print(f"[{report_id}] Pool is empty and not refilling. Triggering emergency refill.")
            report["is_refilling"] = True
            refill_thread = threading.Thread(target=background_refill, args=(report_id,))
            refill_thread.start()
            return jsonify({"error": "No questions available, starting emergency refill. Please wait."}), 503

    # â¬‡ï¸â¬‡ï¸â¬‡ï¸ ì—¬ê¸°ê°€ í•µì‹¬ ë¡œì§ â¬‡ï¸â¬‡ï¸â¬‡ï¸
    # 1. í’€ì—ì„œ í•˜ë‚˜ë¥¼ ë½‘ì•„ì„œ ë°˜í™˜
    next_question = pool.pop(0)
    
    # 2. (í•µì‹¬) ë‚¨ì€ ì§ˆë¬¸ì´ 2ê°œ ì´í•˜ì´ê³ , *í˜„ì¬ ë¦¬í•„ ì¤‘ì´ ì•„ë‹ ë•Œ*
    if len(pool) <= 2 and not is_refilling:
        print(f"[{report_id}] Pool size ({len(pool)}) <= 2. Triggering background refill.")
        # ì¦‰ì‹œ ì ê¸ˆ
        report["is_refilling"] = True
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        refill_thread = threading.Thread(target=background_refill, args=(report_id,))
        refill_thread.start()
    # â¬†ï¸â¬†ï¸â¬†ï¸ í•µì‹¬ ë¡œì§ ë â¬†ï¸â¬†ï¸â¬†ï¸

    # (ì„ íƒ) ë½‘ì€ ì§ˆë¬¸ì„ QA ê¸°ë¡ìœ¼ë¡œ ì´ë™
    if "qa_history" not in report:
        report["qa_history"] = []

    report["qa_history"].append({
        "question": next_question.get("question", "Failed to parse question"),
        "type": next_question.get("type", "unknown"),
        "answer": None # ë‹µë³€ ëŒ€ê¸°
    })

    return jsonify(next_question)

@app.route("/api/report/<report_id>/question/deep-dive", methods=["POST"])
def post_deep_dive_question(report_id):
    """
    POST /api/report/<report_id>/question/deep-dive
    ì‚¬ìš©ìê°€ ë‹µë³€ì„ ì œì¶œí•˜ê³  ì‹¬í™” ì§ˆë¬¸ì„ ìš”ì²­í•  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    
    JSON Body:
    {
        "original_question": "...",
        "user_answer": "..."
    }
    """
    report = analysis_results.get(report_id)
    if not report:
        return jsonify({"error": "Report not found"}), 404
        
    data = request.json
    original_question = data.get("original_question")
    user_answer = data.get("user_answer")
    
    if not original_question or not user_answer:
        return jsonify({"error": "Missing original_question or user_answer"}), 400

    # (ì°¸ê³ ) qa_history ì—…ë°ì´íŠ¸ ë¡œì§ì€ ì—¬ê¸°ì„œ ìƒëµ
    
    # ì‹¬í™” ì§ˆë¬¸ ìƒì„±
    deep_dive_question = generate_deep_dive_question(
        original_question,
        user_answer,
        report["summary"] # ì›ë³¸ ìš”ì•½ë³¸ì„ ë§¥ë½ìœ¼ë¡œ ì „ë‹¬
    )
    
    if not deep_dive_question:
        return jsonify({"error": "Failed to generate deep-dive question"}), 500

    return jsonify({"question": deep_dive_question})
    
# --- 4. (ì„ íƒ ì‚¬í•­) ë£¨íŠ¸ í™•ì¸ìš© ---
@app.route("/")
def hello_world():
    return jsonify({"message": "AITA Backend is running!"})
